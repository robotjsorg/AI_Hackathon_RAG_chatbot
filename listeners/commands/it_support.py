from slack_bolt import Ack, Respond
from logging import Logger
import ollama
# TODO: Import local RAG server

# Replace with your actual channel ID
IT_SUPPORT_CHANNEL_ID = "C07TFNLM4LW"

# TODO: Get RAG output and feed into PROMPT TEMPLATE
PROMPT_TEMPLATE = ("You are an IT support. I'll ask you a question. If it's related to IT, please give me a concise paragraph answer."
                   "Otherwise, just reply with 'I can only answer IT questions \n"
                   "{prompt}")

def generate_llm_response(prompt):
    llm_prompt = PROMPT_TEMPLATE.format(prompt=prompt)
    response = ollama.chat(model='llama3.2', messages=[
        {
            'role': 'user',
            'content': llm_prompt,
        },
    ])
    return response['message']['content']

# Out of scope
# def converse_with_ollama(initial_question, model='llama3.2'):
#     messages = [{'role': 'user', 'content': initial_question}]
#     while True:
#         # Send the messages to Ollama
#         response = ollama.chat(model=model, messages=messages)
#         assistant_reply = response['content']
#         print(f"Assistant: {assistant_reply}\n")
#
#         # Append the assistant's reply to the conversation
#         messages.append({'role': 'assistant', 'content': assistant_reply})
#
#         # Get the next user input
#         user_input = input("You: ")
#         if user_input.lower() in ('exit', 'quit'):
#             break
#         messages.append({'role': 'user', 'content': user_input})

# TODO: Prompt message to IT person, timeout after 30s, then retrieve response from ollama
def it_support_callback(command, ack: Ack, respond: Respond, logger: Logger):
    try:
        ack()
        channel_id = command['channel_id']
        user_id = command['user_id']
        user_input = command.get('text', '')

        if channel_id != IT_SUPPORT_CHANNEL_ID:
            respond(
                response_type="ephemeral",
                blocks=[
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": f"<@{user_id}> requested IT support: {user_input}"
                        }
                    },
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": "Currently, we can't help you. You can call *123-456-7890* for help."
                        }
                    }
                ]
            )
            logger.info(f"Unauthorized use of /it-support by <@{user_id}> in channel <#{channel_id}>.")
            return

        ollama_output = generate_llm_response(user_input)
        print(ollama_output)
        respond(
            response_type="in_channel",
            blocks=[
                # User's request
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"*<@{user_id}> requested IT support:*\n>{user_input}"
                    }
                },
                # Divider
                {
                    "type": "divider"
                },
                # Bot's response
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f":robot_face: *Slackbot Response:*\n{ollama_output}"
                    }
                },
                # Context block indicating it's generated by the Slackbot
                {
                    "type": "context",
                    "elements": [
                        {
                            "type": "mrkdwn",
                            "text": "_Generated by Slackbot_"
                        }
                    ]
                }
            ]
        )
    except Exception as e:
        logger.error(f"Error in it_support_callback: {e}")